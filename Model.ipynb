{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Dependencies**"
      ],
      "metadata": {
        "id": "EuM6K4QXxuNO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XJQsD08qxkU9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DarkNet-53**"
      ],
      "metadata": {
        "id": "OiI82I9nxxut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the characteristics of a convolutional block in our CNN\n",
        "class ConvUnit(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    super(ConvUnit, self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=False)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.leaky_relu = nn.LeakyReLU(0.1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.leaky_relu(self.bn(self.conv(x)))"
      ],
      "metadata": {
        "id": "jwXqX6Mfx406"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the characteristics of a residual unit in our CNN\n",
        "class ResidualUnit(nn.Module):\n",
        "  def __init__(self, in_channels):\n",
        "    super(ResidualUnit, self).__init__()\n",
        "    self.conv1 = ConvUnit(in_channels, in_channels//2, kernel_size=1, stride=1, padding=0)\n",
        "    self.conv2 = ConvUnit(in_channels//2, in_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # skip connection\n",
        "    return x + self.conv2(self.conv1(x))"
      ],
      "metadata": {
        "id": "NAdT8bAL0pt_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Outline the CNN itself\n",
        "\n",
        "class DarkNet53(nn.Module):\n",
        "  def __init_(self):\n",
        "    super(DarkNet53, self).__init__()\n",
        "    # First convolutional layer\n",
        "    self.conv1 = ConvUnit(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    # Downsample (reduce dimensionality)\n",
        "    self.conv2 = ConvUnit(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    # First residual unit + skip connection\n",
        "    self.res1 = self.make_layer(ResidualUnit(64, 1))\n",
        "\n",
        "    self.conv3 = ConvUnit(in_channels=64, out_channels=128, kernel_size=3, stride=2, padding=1)\n",
        "    self.res2 = self.make_layer(ResidualUnit(128, 2))\n",
        "    self.conv4 = ConvUnit(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=1)\n",
        "    self.res3 = self.make_layer(ResidualUnit(256, 8))\n",
        "    self.conv5 = ConvUnit(in_channels=256, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
        "    self.res4 = self.make_layer(ResidualUnit(512, 8))\n",
        "    self.conv6 = ConvUnit(in_channels=512, out_channels=1024, kernel_size=3, stride=2, padding=1)\n",
        "    self.res5 = self.make_layer(ResidualUnit(1024, 4))\n",
        "\n",
        "  def make_layer(self, unit, out_channels, num_units):\n",
        "    layers=[]\n",
        "    for _ in range(num_units):\n",
        "      layers.append(unit(out_channels))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.res1(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.res2(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.res3(x)\n",
        "    x = self.conv5(x)\n",
        "    x = self.res4(x)\n",
        "    x = self.conv6(x)\n",
        "    x = self.res5(x)\n",
        "    return x  # our feature map"
      ],
      "metadata": {
        "id": "ZzmrT75l0wxf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**\"YOLO Layer\"**\n",
        "\n",
        "After our Darknet53 CNN extracts the features, we use the 'yolo,' layer to complete object detection and classification in a single forward pass."
      ],
      "metadata": {
        "id": "GNu8B1P-4nFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOLayer(nn.Module):\n",
        "  def __init__(self, in_channels, num_classes, anchors):\n",
        "    super(YOLOLayer, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.num_anchors = len(anchors)\n",
        "    # Output layer\n",
        "    self.conv = nn.Conv2d(in_channels, self.num_anchors * (5 + num_classes), kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, _, grid_size, _ = x.shape\n",
        "    prediction = self.conv(x).view(batch_size, self.num_anchors, 5 + self.num_classes, grid_size, grid_size)\n",
        "    prediction = prediction.premute(0, 1, 3, 4, 2).contiguous()\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "g_eWk1oS5OIe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **YOLOv3**"
      ],
      "metadata": {
        "id": "pMUsXaGb6v8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOv3(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(YOLOv3, self).__init__()\n",
        "    self.base = DarkNet53()\n",
        "    self.yolo1 = YOLOLayer(1024, num_classes, anchors=[(116, 90), (156, 198), (373, 326)])\n",
        "    self.yolo2 = YOLOLayer(512, num_classes, anchors=[(30, 61), (62, 45), (59, 119)])\n",
        "    self.yolo3 = YOLOLayer(256, num_classes, anchors=[(10, 13), (16, 30), (33, 23)])\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.base(x)\n",
        "    return self.yolo1(x), self.yolo2(x), self.yolo3(x) # (Three detection heads)"
      ],
      "metadata": {
        "id": "BbLEKORT60wf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss Function**\n",
        "\n",
        "Three phase, Squared Error Approach\n",
        "\n",
        "1) Bounding box error - heavy penalty\n",
        "\n",
        "2) Incorrect object detected in cell\n",
        "\n",
        "3) Error between prediction and target prediction"
      ],
      "metadata": {
        "id": "9OctUQa58Mgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOLoss(nn.Module):\n",
        "  def __init__(self, num_classes):\n",
        "    super(YOLOLoss, self).__init__()\n",
        "    self.num_classes = num_classes\n",
        "    self.mse = nn.MSELoss()\n",
        "    self.bce = nn.BCEWithLogitsLoss()\n",
        "    self.ce = nn.CrossEntropyLoss()\n",
        "\n",
        "  def forward(self, predictions, targets):\n",
        "    # 1 : loss for bounding box (x,y coords , width, height)\n",
        "    box_loss = self.mse(predictions[..., :4], targets[..., :4])\n",
        "\n",
        "    # 2 : object confidence\n",
        "    conf_loss = self.bce(predictions[..., 4], targets[..., 4])\n",
        "\n",
        "    # 3 : class predictions\n",
        "    class_loss = self.ce(predictions[..., 5:], targets[..., 5:].argmax(-1))\n",
        "\n",
        "    total_loss = box_loss + conf_loss + class_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "NCMH3G1o8nNN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = YOLOv3(num_classes=2)"
      ],
      "metadata": {
        "id": "0bwC26Mp8AYX"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}